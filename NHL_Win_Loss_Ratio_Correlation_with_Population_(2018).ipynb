{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXcQZIEzhgU9mQazdVAVwf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SrishtiTyagii/coursework/blob/main/NHL_Win_Loss_Ratio_Correlation_with_Population_(2018).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NHL Win/Loss Ratio Correlation with Population (2018)\n",
        "This code calculates the Pearson correlation coefficient between the win/loss ratio of NHL (National Hockey League) teams in 2018 and the population of the metropolitan area where the teams are based. The goal is to determine if there is any correlation between the size of a city's population and the performance of its NHL team(s)."
      ],
      "metadata": {
        "id": "KmJ3fpeebGhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Importing Required Libraries"
      ],
      "metadata": {
        "id": "kIjIXBhvjTCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import re"
      ],
      "metadata": {
        "id": "eGYo2BcPheIy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* pandas: For data manipulation and reading data from files.\n",
        "* numpy: For numerical operations, particularly handling NaN values.\n",
        "* scipy.stats: To calculate the Pearson correlation coefficient.\n",
        "* re: To perform regular expression operations for string cleaning."
      ],
      "metadata": {
        "id": "5GLG3vsljcEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Loading and Cleaning City Data"
      ],
      "metadata": {
        "id": "Awz8hMVVjgpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cities = pd.read_html(\"/content/wikipedia_data.html\")[1]\n",
        "cities = cities.iloc[:-1, [0, 3, 5, 6, 7, 8]]\n",
        "cities.rename(columns={\"Population (2016 est.)[8]\": \"Population\"}, inplace=True)\n",
        "cities['NFL'] = cities['NFL'].str.replace(r\"\\[.*\\]\", \"\")\n",
        "cities['MLB'] = cities['MLB'].str.replace(r\"\\[.*\\]\", \"\")\n",
        "cities['NBA'] = cities['NBA'].str.replace(r\"\\[.*\\]\", \"\")\n",
        "cities['NHL'] = cities['NHL'].str.replace(r\"\\[.*\\]\", \"\")\n"
      ],
      "metadata": {
        "id": "A2a9USEnjkYi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* pd.read_html reads the Wikipedia table containing metropolitan areas and their associated sports teams.\n",
        "* The iloc function selects relevant columns from the table, which include city name, population, and team names for the NFL, MLB, NBA, and NHL.\n",
        "* We clean up the team names by removing any references or footnotes (denoted by square brackets) using str.replace()."
      ],
      "metadata": {
        "id": "sdV4KJ0WjzbD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Extracting NHL Team Names"
      ],
      "metadata": {
        "id": "mSVOktuZj5Vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Big4 = 'NHL'\n",
        "team = cities[Big4].str.extract('([A-Z]{0,2}[a-z0-9]*\\ [A-Z]{0,2}[a-z0-9]*|[A-Z]{0,2}[a-z0-9]*)')\n",
        "team['Metropolitan area'] = cities['Metropolitan area']\n",
        "team = pd.melt(team, id_vars=['Metropolitan area']).drop(columns=['variable']).replace(\"\", np.nan).replace(\"â€”\", np.nan).dropna().reset_index().rename(columns={\"value\": \"team\"})\n",
        "team = pd.merge(team, cities, how='left', on='Metropolitan area').iloc[:, 1:4]\n",
        "team = team.astype({'Metropolitan area': str, 'team': str, 'Population': int})\n",
        "team['team'] = team['team'].str.replace('[\\w.]*\\ ', '')"
      ],
      "metadata": {
        "id": "HPjLABqcj7rd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We extract the NHL team names for each city using a regular expression, which captures team names with or without spaces. * This handles cases where multiple teams are associated with a single metropolitan area.\n",
        "* The pd.melt() function transforms the DataFrame so that each row corresponds to a single team and its corresponding city.\n",
        "* The resulting DataFrame is cleaned, merged with the cities DataFrame to include population data, and the team names are cleaned further."
      ],
      "metadata": {
        "id": "3akOnvJDkEup"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Loading and Cleaning NHL Win/Loss Data"
      ],
      "metadata": {
        "id": "1m66lV4XkUnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_df = pd.read_csv(\"/content/nhl.csv\")\n",
        "_df = _df[_df['year'] == 2018]\n",
        "_df['team'] = _df['team'].str.replace(r'\\*', \"\")\n",
        "_df = _df[['team', 'W', 'L']]"
      ],
      "metadata": {
        "id": "7pPCULMCkaS8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We load the NHL win/loss data from a CSV file and filter for the 2018 season.\n",
        "* Asterisks are removed from the team names, and only the relevant columns (team, W, L) are kept."
      ],
      "metadata": {
        "id": "Y5_h6Waxklxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Handling Invalid Rows"
      ],
      "metadata": {
        "id": "idR6H5RMkpFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropList = []\n",
        "for i in range(_df.shape[0]):\n",
        "    row = _df.iloc[i]\n",
        "    if row['team'] == row['W'] and row['L'] == row['W']:\n",
        "        dropList.append(i)\n",
        "_df = _df.drop(dropList)"
      ],
      "metadata": {
        "id": "MeAruCVeksna"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* This section removes any rows where the team name is incorrectly populated with win or loss values, which can happen due to data formatting issues."
      ],
      "metadata": {
        "id": "99jktYDOkxkw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Cleaning Team Names and Calculating Win/Loss Ratios"
      ],
      "metadata": {
        "id": "PmFE8Tl9kzgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_df['team'] = _df['team'].str.replace('[\\w.]* ', '')\n",
        "_df = _df.astype({'team': str, 'W': int, 'L': int})\n",
        "_df['W/L%'] = _df['W'] / (_df['W'] + _df['L'])"
      ],
      "metadata": {
        "id": "vJEVaY-Pky16"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The team names are cleaned by removing extra characters or words, and we ensure that the W (wins) and L (losses) columns are integers.\n",
        "* The win/loss ratio (W/L%) is calculated by dividing wins by the total number of games played."
      ],
      "metadata": {
        "id": "ArZUBI_Rk81b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Merging City and Team Data"
      ],
      "metadata": {
        "id": "OlW3NlCpk_-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merge = pd.merge(team, _df, how='outer', on='team')\n",
        "merge = merge.groupby('Metropolitan area').agg({'W/L%': np.nanmean, 'Population': np.nanmean})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkytu7nylCxx",
        "outputId": "9db666d3-9970-4179-e473-e6b34f5fd7ec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-07a30d12085d>:2: FutureWarning: The provided callable <function nanmean at 0x793a92f4e440> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
            "  merge = merge.groupby('Metropolitan area').agg({'W/L%': np.nanmean, 'Population': np.nanmean})\n",
            "<ipython-input-11-07a30d12085d>:2: FutureWarning: The provided callable <function nanmean at 0x793a92f4e440> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
            "  merge = merge.groupby('Metropolitan area').agg({'W/L%': np.nanmean, 'Population': np.nanmean})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We merge the city population data (team) with the NHL win/loss data (_df) based on the team column.\n",
        "* After merging, we group by Metropolitan area to calculate the average win/loss ratio and population for cities with multiple teams."
      ],
      "metadata": {
        "id": "uW-k-BkRlH1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Correlation Calculation"
      ],
      "metadata": {
        "id": "QQYDjBrVlKQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "population_by_region = merge['Population']\n",
        "win_loss_by_region = merge['W/L%']\n",
        "\n",
        "assert len(population_by_region) == len(win_loss_by_region), \"Your lists must be the same length\"\n",
        "assert len(population_by_region) == 28, \"There should be 28 teams being analyzed for NHL\"\n",
        "\n",
        "return stats.pearsonr(population_by_region, win_loss_by_region)[0]\n",
        "correlation = calculate_pearson_correlation()\n",
        "print(correlation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "IkaZ09G5lOQ3",
        "outputId": "80ea6247-e6ab-40fa-d826-7e6e4daf7ec3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "'return' outside function (<ipython-input-15-fb85810504db>, line 7)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-fb85810504db>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    return stats.pearsonr(population_by_region, win_loss_by_region)[0]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
          ]
        }
      ]
    }
  ]
}